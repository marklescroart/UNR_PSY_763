{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution & Smoothing\n",
    "\n",
    "In this notebook, we will review the operation of *convolution*, and how it is used to model the hemodynamic response function in fMRI. We will also show how convolution with a Gaussian kernel smooths data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Inline plots\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "# A little config for image plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'equal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hemodynamic response function!\n",
    "The equation for the HRF given in Boynton et al 1996 is:\n",
    "\n",
    "# $h(t) = \\frac{(t/\\tau)^{n-1}e^{-t/\\tau}}{\\tau(n-1)!}$\n",
    "\n",
    "$t$ is time\n",
    "\n",
    "$\\tau$ is time constant, which governs the width of the function\n",
    "\n",
    "$n$ governs the delay in the response, and must be an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Put this into python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from scipy.special import factorial\n",
    "\n",
    "def gammafun(t, tau, n):\n",
    "    num = (t/tau)**(n-1) * np.e**(-t/tau)\n",
    "    denom = tau*factorial(n-1)\n",
    "    return num/denom\n",
    "\n",
    "## BELOW HERE IS JUST FOR FANCY PLOTTING ##\n",
    "\n",
    "from ipywidgets import widgets, interactive\n",
    "\n",
    "def gamma_plot(tau, n):\n",
    "    fig, ax = plt.subplots(num=33, figsize=(6,4))\n",
    "    # What might happen with different sampling of T here?\n",
    "    t = np.linspace(0, 32, 33) # 32 seconds worth\n",
    "    #t = np.linspace(0, 32, 100) # 32 seconds worth\n",
    "    # Note that there is a fudge here to make the units of n more sensible! \n",
    "    # (adding one to it makes n reflect the number of seconds to the peak\n",
    "    # of the function, when tau = 1)\n",
    "    ax.plot(t, gammafun(t, tau, n+1), '.-')\n",
    "    ax.set_ylim(-0.01, 0.50)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.grid(which='both')\n",
    "    plt.show()\n",
    "\n",
    "tau = widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=2.0,\n",
    "    step=0.1,\n",
    "    description='$\\\\tau$',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',)\n",
    "\n",
    "n = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=2,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='n',\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',)\n",
    "\n",
    "interactive_plot = interactive(gamma_plot, tau=tau, n=n)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE that this mathematical approximation of this HRF is NOT necessarily set in stone - there is no ground truth that says the HRF is and always should be a gamma function. This is a good-enough approximation (there are others out there that some say are slightly better). There is a large literature about estimating HRF parameters (as parameters of a gamma function and otherwise). One clear indicator of the kloodgy nature of the gamma function as an approximation of the HRF is that derivatives of the gamma function are often used along with it. \n",
    "\n",
    "The next cells show that you can create slightly different shapes of the HRF by fixing a gamma function and then adding a scaled version of the function's derivative back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(32)\n",
    "g = gammafun(t, tau=1, n=6)\n",
    "# You may ask yourself, What does np.diff do on the next line? \n",
    "# Perhaps create a new cell and use the help: np.diff?\n",
    "dg = np.hstack([0, np.diff(g)]) \n",
    "ddg = np.hstack([0, np.diff(dg)])\n",
    "plt.plot(g, 'k', lw=2, label='Base HRF')\n",
    "plt.plot(dg, label='First derivative')\n",
    "plt.plot(ddg, label='Second derivative')\n",
    "plt.legend(frameon=False, fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g, 'k-', lw=2, label='Original HRF')\n",
    "plt.plot(g + 2 * dg, label='HRF + 2 * $\\delta$HRF')\n",
    "plt.plot(g - 2 * dg, label='HRF - 2 * $\\delta$HRF')\n",
    "plt.legend(frameon=False, fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve the HRF with a stimulus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a canonical HRF\n",
    "t = np.arange(32) # 32 seconds @TR = 1 second\n",
    "hrf = gammafun(t, tau=1, n=6+1)\n",
    "\n",
    "plt.plot(t, hrf, '.-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: the hrf principally used in this notebook has been created for a TR of 1 second. It's possible to create an HRF for arbitrary TRs - here is the way to create one for a TR of 2 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(32) \n",
    "t2 = np.arange(0, 32, 2) # 3rd argument here is step size (2)\n",
    "tau = 1 \n",
    "n = 5\n",
    "y = gammafun(t, tau, n)\n",
    "y2 = gammafun(t2, tau, n)\n",
    "plt.plot(t2, y2, marker='o', ls='--', markerfacecolor='None', markersize=8, label='TR = 2');\n",
    "plt.plot(t, y, marker='*', ls='--', label='TR = 1');\n",
    "plt.legend(frameon=False, fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the line for TR=2 has only half the number of points sampled as the other line! \n",
    "... But we will just use the first one we generated for the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single discrete stimulus that appears at time 0\n",
    "stimulus = np.zeros(t.shape)\n",
    "stimulus[0] = 1\n",
    "\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, stimulus)\n",
    "\n",
    "# There is a better function that we can use to make this plot more explicit\n",
    "plt.subplot(122)\n",
    "plt.stem(t, stimulus, linefmt='k-', markerfmt='.', basefmt='k-', label='Stimulus');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be plotting stimulus / response pairs several times\n",
    "# Hence, here is a function that can plot these two together\n",
    "def stim_resp_plot(t, stimulus, response, yl=(-0.2, 1.2), label_stim='Stimulus', label_resp='BOLD response (HRF)'):\n",
    "    \"\"\"Plot stimulus and response.\"\"\"\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.stem(t, stimulus, linefmt='k-', markerfmt='.', basefmt='k-', label=label_stim)\n",
    "    plt.plot(t, response, 'r.-', label=label_resp)\n",
    "    plt.ylim(yl)\n",
    "    plt.xlim([-1,t.max()+1])\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Response (arbitrary units)')\n",
    "    _ = plt.legend()\n",
    "\n",
    "# Plot\n",
    "stim_resp_plot(t, stimulus, hrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # Total time points (TRs)\n",
    "t = np.arange(n,)\n",
    "\n",
    "# No stimulus\n",
    "stimuli = np.zeros((n))\n",
    "\n",
    "# We assume no response\n",
    "response = np.zeros((n))\n",
    "\n",
    "# Here we plot the function\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "A few cells above we plotted how the signal changes when we have a stimulus at time 0. \n",
    "\n",
    "Now, imagine we have a stimulus at time `i=10`. What do you expect will happen when we plot the stimulus and response?\n",
    "\n",
    "Hint: This stimulus will create an HRF that will be *added* to the signal from times i to times i + hrf_length (hrf_length is the length of our canonical HRF, which was 32 above).\n",
    "\n",
    "Attention: Make sure you modify the response by adding something to its values, and not only changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "i = 10\n",
    "stimuli[i] = 1\n",
    "hrf_length = len(hrf)\n",
    "response[range(i,i+hrf_length)] += hrf\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "\n",
    "Now let's say that there were 3 event onsets, one at `i=10`, one at `i=70` and one at `i=150`, plot the resulting activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "indices = [10, 70, 150]\n",
    "stimuli = np.zeros((n,))\n",
    "response = np.zeros((n,))\n",
    "for i in indices:\n",
    "    stimuli[i] = 1\n",
    "    response[i:i + hrf_length] += hrf\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Now say that the stimuli are closer together than the length of the hemodynamic function: let's say they occur at times 10, 21, 25, 70, 71,74, 75, 80 and 150, what happens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "indices = [10, 21, 70, 71, 74, 75, 80, 150]\n",
    "stimuli = np.zeros((n,))\n",
    "response = np.zeros((n,))\n",
    "for i in indices:\n",
    "    stimuli[i] = 1\n",
    "    # NOTE! This next line is where you see the difference between \n",
    "    # SUBSTITUTING values into response (response[blah] = hrf) vs\n",
    "    # ADDING values to response (response[blah] += hrf)\n",
    "    response[i:i + hrf_length] += hrf # delete the `+` to see what happens. But then put it back!\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below implements a slightly different answer, which we did in class. This one does two separate loops, one to define the impulse responses in the stimulus, and one to do something very close to a convolution (the difference between this and the above loop is that this (a) operates on *every* value in `stimuli` to generate the response, not just the values that are ones, and (b) multiplies the hrf by the value of the stimulus. The latter is not critical here, since the stimulus value is just one, but will make a difference if the stimulus takes on values other than 0 or 1). \n",
    "\n",
    "This implementation also highlights the complexities arising from edge effects in convolution (see comment in code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define stimuli, response\n",
    "stimuli = np.zeros((n))\n",
    "response = np.zeros((n))\n",
    "# Loop over indices\n",
    "for i in [10, 21, 25, 70, 71,74, 75, 80, 150]:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "for i in np.arange(len(stimuli)):\n",
    "    # Note the index on hrf - for values of `i` near the end of `response`, the length of \n",
    "    # response[i:i+len(hrf)] will be SHORTER than hrf, so hrf must be indexed as well. \n",
    "    response[i:i+len(hrf)] += hrf[:len(stimuli)-i] * stimuli[i]\n",
    "# Fancy plot\n",
    "stim_resp_plot(t, stimuli, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use np.convolve to do effectively this same thing.\n",
    "rr = np.convolve(stimuli, hrf, mode='full')\n",
    "# rr is longer than stimuli by the length of the hrf, so we must crop it: \n",
    "rr = rr[:len(stimuli)]\n",
    "stim_resp_plot(t, stimuli, rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: using functions for convolution gets trickier, because you have to pay attention to edge effects, and how you want the convolution kernel to be centered on your data. For example, for the HRF, you want the full function to occur AFTER stimulus onset. However, if you want to smooth your data, you may want the peak of the convolution kernel to be centered on each point.\n",
    "\n",
    "**Blackboard chat...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General case of 1D smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some noise data\n",
    "n_timepoints = 100\n",
    "data = np.random.randn(n_timepoints,)\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a gaussian smoothing kernel\n",
    "n_c = 15\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "x = np.linspace(-3, 3, n_c)\n",
    "g = np.e**(-x**2)\n",
    "g /= np.sum(g)\n",
    "print(np.sum(g))\n",
    "plt.plot(x,g, '.-')\n",
    "plt.grid(axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help!\n",
    "np.convolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple case\n",
    "s = np.zeros((100,))\n",
    "s[5] = 1\n",
    "s_c = np.convolve(s, g, mode='same')\n",
    "s_c2 = np.convolve(s, g, mode='full')\n",
    "s_c2 = s_c2[n_:-n_]\n",
    "print(np.allclose(s_c2, s_c))\n",
    "print(s_c.shape)\n",
    "plt.plot(s);\n",
    "plt.plot(s_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = np.convolve(data, g, mode='full')\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "data_c = data_c[n_:-n_]\n",
    "plt.plot(data, label='original')\n",
    "plt.plot(data_c, label='smoothed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Create a filter to take a block average rather than a Gaussian kernel. Test it on some simple data (e.g., convolve it with `s` created above), then convolve it with the data above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "# Filter (just ones! of a particular length!)\n",
    "b_len = 5\n",
    "k = np.ones((b_len,))/b_len # if you don't \n",
    "# Simple\n",
    "s_ck = np.convolve(s, k, mode='same')\n",
    "t_s = np.arange(len(s))\n",
    "plt.plot(s)\n",
    "plt.plot(s_ck)\n",
    "# Complex\n",
    "data_ck = np.convolve(data, k, mode='same')\n",
    "t_d = np.arange(len(data))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data, color='gray', label='data')\n",
    "plt.plot(data_c, label='original (Gaussian) smoothing')\n",
    "plt.plot(data_ck, label='block smoothing')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution w/ Gaussian kernel (smoothing) in 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [101, 101]\n",
    "data2d = np.random.randn(*dims)\n",
    "plt.imshow(data2d);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Create a 2D Gaussian kernel! The equation for a 2D Gaussian is:\n",
    "\n",
    "# $g = e^{-\\frac{(x-\\mu_x)^2}{2\\sigma^2_x} + \\frac{(y-\\mu_y)^2}{2\\sigma^2_y}}$\n",
    "\n",
    "$\\sigma_x$ is the standard deviation of the Gaussian in the x dimension\n",
    "\n",
    "$\\sigma_y$ is the standard deviation of the Gaussian in the y dimension\n",
    "\n",
    "Critical to this endeavor is defining the X and Y over which the function will be evaluated. To do that, you need a *grid* of values (arrays of x and y values that vary linearly in the x and y dimensions). To create such a grid, use `np.meshgrid`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 7 # pixels\n",
    "xyrange = np.linspace(-3, 3, kernel_size)\n",
    "x, y = np.meshgrid(xyrange, xyrange)\n",
    "print('x:')\n",
    "print(x)\n",
    "print('y:')\n",
    "print(y)\n",
    "# This x and y should go into the computation of your 2D Gaussian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill me in!\n",
    "g = np.exp(x+y) #...\n",
    "\n",
    "# (better still, make this a function that takes inputs mu_x, mu_y, sigma_x, sigma_y...)\n",
    "def make_gauss(x, y, mu_x, mu_y, sigma_x, sigma_y):\n",
    "    g = 0 #...\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "# 2D gaussian kernel\n",
    "n_c = 15\n",
    "t = np.linspace(-3, 3, n_c)\n",
    "x, y = np.meshgrid(t, t)\n",
    "def make_gauss(x, y, mu_x, mu_y, sigma_x, sigma_y):\n",
    "    g = np.e**(-((x-mu_x)**2/(2*sigma_x**2) + (y-mu_y)**2/(2*sigma_y**2)))\n",
    "    return g / np.sum(g)\n",
    "g2d = make_gauss(x, y, 0, 0, 1, 1)\n",
    "plt.imshow(g2d);\n",
    "# Or try this (to show the x, y range over which this function was actually evaluated) : \n",
    "plt.figure()\n",
    "plt.imshow(g2d, extent=(-3, 3, -3, 3));\n",
    "# Note: there is another function called plt.pcolormesh() that explicity takes x and y values.\n",
    "# look into it if you are curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To smooth the image, convolve this kernel with the image, using a convolve2d function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not in the same library, because python.\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_c = convolve2d(data2d, g2d, mode='full')\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "data2d_c = data2d_c[n_:-n_, n_:-n_]\n",
    "print(data2d_c.shape)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].imshow(data2d);\n",
    "axs[1].imshow(data2d_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()\n",
    "image_c = convolve2d(image, g2d, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax2.imshow(image_c, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "Make it blurrier! How would you blur out more of the coins? DO IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "n_c = 51\n",
    "t = np.linspace(-3, 3, n_c)\n",
    "x, y = np.meshgrid(t, t)\n",
    "g2d_2 = make_gauss(x, y, 0, 0, 1, 1)\n",
    "image_cc = convolve2d(image,g2d_2, mode='same')\n",
    "plt.imshow(image_cc, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing can reveal real signal hidden in noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_noisy = np.random.randn(*dims)\n",
    "data2d_noisy[10:30,10:30] += 0.6\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].imshow(data2d_noisy)\n",
    "data2d_noisy_c = convolve2d(data2d_noisy, g2d, mode='same')\n",
    "axs[1].imshow(data2d_noisy_c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... But also can obscure potentially real variation at a scale smaller than the smoothing kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No-Answer Exercises\n",
    "(Not *exactly* homework...)\n",
    "## 1\n",
    "\n",
    "Create a design matrix as we did last week, and convolve each column of X with the boynton HRF! Use THAT X to generate data (plus some noise) (This is how the fMRI signal is modeled in the Boynton paper!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "B = ...\n",
    "# Convolve X with the HRF function\n",
    "Xc = np.convolve()\n",
    "E = ...\n",
    "Y = X.dot(B) + E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Estimate $\\beta$ from your simulated data using the regression equation from last week. \n",
    "\n",
    "Play with the noise level until your estimated $\\beta$ weights become inaccurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 (Advanced)\n",
    "\n",
    "See if you can create a design matrix that will NOT allow you to accurately estimate B weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
